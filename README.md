# NewsNexus v2.0 - Intelligent News Aggregator MCP Server

A production-ready, intelligent news aggregation system with **sophisticated topic filtering, multi-feed architecture, and MCP server support**. Designed for AI assistants and power users to fetch only relevant, recent news with zero false positives.

[![Python 3.13](https://img.shields.io/badge/python-3.13-blue.svg)](https://www.python.org/downloads/)
[![MCP Protocol](https://img.shields.io/badge/MCP-2024--11--05-green.svg)](https://modelcontextprotocol.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status: Production](https://img.shields.io/badge/Status-Production-brightgreen.svg)]()

## ğŸ¯ Overview

NewsNexus is a sophisticated news aggregator that fetches **only the latest news** (15 days by default) with intelligent topic filtering, priority-based fallback architecture, and parallel multi-feed processing. Built as a **Model Context Protocol (MCP) server** for seamless AI integration.

**Latest Update (Dec 10, 2025):** Fixed Google News RSS parsing bug, updated all 42 Google News URLs to US locale, and enhanced topic keywords to 17 categories with 500+ keywords.

### ğŸŒŸ Key Features

- âœ… **Smart Recent News Filter**: Default 15-day cap ensures only recent/latest/top news (max 365 days)
- âœ… **Intelligent Topic Filtering**: Word boundary matching + 17 topic categories with 500+ keywords
- âœ… **3-Priority Fallback Architecture**: Official RSS â†’ Google News â†’ HTML Scraper
- âœ… **Multi-Feed Parallel Processing**: Fetch 45+ RSS feeds simultaneously across priority domains
- âœ… **Priority-Based Fetching**: Always respects domain priority order (NDTV > Indian Express > etc.)
- âœ… **Flexible Domain Matching**: Use partial names (`openai` â†’ `openai.com`, `ndtv` â†’ `ndtv.com`)
- âœ… **Smart Deduplication**: URL and title-based deduplication with fuzzy matching
- âœ… **Reverse Chronological Order**: Articles always newest first
- âœ… **Fast Performance**: ~2-3s per domain with parallel fetching and smart timeout management
- âœ… **Production-Ready**: 8-layer filtering engine, comprehensive error handling, structured logging

---

## ğŸ“Œ Recent Fixes & Updates (December 2025)

### âœ¨ December 10, 2025 - Google News Fix & Topic Keyword Expansion

**Problems Fixed:**
1. **Google News RSS articles all deduplicated to 1** - `source.href` only contained domain, not full article URL
2. **Topic filter too strict** - Only matched exact keyword, missed related terms

**Solutions Implemented:**
```python
# Fix 1: Keep unique Google redirect URLs instead of extracting domain
# Google redirect URLs like news.google.com/rss/articles/... are unique and work when clicked

# Fix 2: Enhanced topic keywords with 17 categories
TOPIC_KEYWORDS = {
    'ai': ['ai', 'artificial intelligence', 'chatgpt', 'openai', 'gemini', 'claude', ...],  # 56 keywords
    'tech': ['technology', 'software', 'startup', 'gadget', 'smartphone', ...],  # 60 keywords
    'crypto': ['bitcoin', 'ethereum', 'blockchain', 'nft', 'defi', ...],  # 25 keywords
    'startup': ['unicorn', 'funding', 'venture capital', 'founder', ...],  # 28 keywords
    'gaming': ['esports', 'playstation', 'xbox', 'pubg', 'fortnite', ...],  # 26 keywords
    # + 12 more categories: cricket, finance, sports, politics, health, entertainment, 
    #                        education, auto, travel, weather, realestate, jobs
}
```

**Additional Changes:**
- Updated all 42 Google News URLs to US locale (`&hl=en-US&gl=US&ceid=US:en`) for better results
- Fixed TechCrunch RSS URL (was pointing to fake feedburner feed)
- Synced TOPIC_KEYWORDS between `main.py` and `fetch_topic_news.py`

### âœ¨ December 9, 2025 - Critical Topic Filtering Fix

**Problem Identified:**
- Substring matching was causing false positives: `"ai" in "paint"` â†’ `True`, `"ai" in "Ukraine"` â†’ `True`
- Priority domain AI fetches returned only 4 articles instead of expected 8+
- Articles about generic topics (sports, politics) were incorrectly labeled as AI-related

**Root Cause:**
- `filter_articles()` in `main.py` used simple substring matching: `if topic_lower not in text`
- `is_ai_related()` in `get_ai_news_with_fallback.py` used substring matching instead of word boundaries

**Solution Implemented:**
```python
# Before (broken):
if topic_lower and topic_lower not in text:
    continue

# After (fixed):
if topic_lower:
    if not re.search(r'\b' + re.escape(topic_lower) + r'\b', text):
        continue
```

**Impact:**
- âœ… Priority domain AI fetches now return **8 articles from premium Indian sources only**
- âœ… Zero false positives: "Ukraine" no longer matches "AI" filter
- âœ… Correct fallback behavior: Only uses non-priority sources when priority sources insufficient
- âœ… Proper keyword matching: "ChatGPT", "Machine Learning", "Anthropic Claude" all correctly identified

**Files Modified:**
1. `main.py` - Line 1367: Updated `filter_articles()` function with word boundary matching
2. `get_ai_news_with_fallback.py` - Line 67: Updated `is_ai_related()` function with word boundary matching
3. `fetch_ai_news.py` - Created wrapper to suppress logging for clean JSON output

**Testing Results:**
```
BEFORE FIX:
- ndtv.com: 0 AI articles
- indianexpress.com: 1 AI article
- timesofindia.indiatimes.com: 0 AI articles
- hindustantimes.com: 0 AI articles
- gadgets360.com: 0 AI articles
- economictimes.indiatimes.com: 3 AI articles
Total: 4 from priority, then 4 fallback to non-priority (Wired, Verge, TechCrunch)

AFTER FIX:
- ndtv.com: "The Year AI Became Personal: 10 Tools..."
- timesofindia.indiatimes.com: "Google's AI hub Tarluvada..."
- economictimes.indiatimes.com: "SoftBank, Nvidia looking to invest in Skild AI..."
- economictimes.indiatimes.com: "Intel signs pact for AI PC solutions..."
- economictimes.indiatimes.com: "Trump signs executive order on AI..."
- economictimes.indiatimes.com: "IBM buys Confluent for AI-driven demand..."
- ndtv.com: "OpenAI Claims Increased Enterprise Usage..."
- economictimes.indiatimes.com: "Sebi eases AIF rules, allows AI-only schemes..."
Total: 8 from priority domains only âœ…
```

### ğŸ§¹ December 9, 2025 - Production Code Cleanup

**Removed:**
- 14 test Python scripts (test_*.py, compare_sources.py, diagnose_articles.py, etc.)
- 19 documentation markdown files (temporary implementation notes)
- 4 output text files (ai_output.txt, comparison.txt, etc.)
- 3 temporary JSON files (ai_news_*.json)
- Python cache directories (__pycache__, .pytest_cache)
- Test artifacts (.coverage, tech_test.txt)

**Result:** Clean production structure with only 4 core Python files

---

## ğŸ—ï¸ Architecture



```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NewsNexus v2.0 - MCP Server                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  MCP Tools:                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ â€¢ get_articles(domain, topic?, location?, lastNDays?)            â”‚   â”‚
â”‚  â”‚ â€¢ get_top_news(count?, topic?, location?, lastNDays?)            â”‚   â”‚
â”‚  â”‚ â€¢ health_check()                                                 â”‚   â”‚
â”‚  â”‚ â€¢ get_metrics()                                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                              â”‚
â”‚                           â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              8-Layer Filtering Engine                            â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  1. Days Filter (Default: 15 days, Max: 365)                    â”‚   â”‚
â”‚  â”‚  2. Topic Filter (Keyword search in title/summary/tags)         â”‚   â”‚
â”‚  â”‚  3. Location Filter (Keyword search)                            â”‚   â”‚
â”‚  â”‚  4. Priority-based Site Selection (Top 6-12 sites)              â”‚   â”‚
â”‚  â”‚  5. URL Deduplication (Normalized URLs)                         â”‚   â”‚
â”‚  â”‚  6. Title Deduplication (Fuzzy matching)                        â”‚   â”‚
â”‚  â”‚  7. Response Time Filtering (2s timeout per source)             â”‚   â”‚
â”‚  â”‚  8. Article Count Limiting (Default: 10, Max: 100)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                              â”‚
â”‚                           â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Priority-Grouped Parallel Fetching Strategy              â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  Priority 1: Official RSS Feeds (Multiple per site)             â”‚   â”‚
â”‚  â”‚  â”œâ”€ Fetch all RSS feeds in parallel (max 8 workers)             â”‚   â”‚
â”‚  â”‚  â”œâ”€ Deduplicate by URL across all feeds                         â”‚   â”‚
â”‚  â”‚  â”œâ”€ If â‰¥5 articles â†’ SUCCESS, return results                    â”‚   â”‚
â”‚  â”‚  â””â”€ If <5 articles â†’ Try Priority 2                             â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  Priority 2: Google News RSS (Quality-checked)                  â”‚   â”‚
â”‚  â”‚  â”œâ”€ Resolve redirect URLs (2s timeout)                          â”‚   â”‚
â”‚  â”‚  â”œâ”€ Quality check: â‰¥50% valid URLs required                     â”‚   â”‚
â”‚  â”‚  â”œâ”€ If â‰¥5 articles + valid â†’ SUCCESS                            â”‚   â”‚
â”‚  â”‚  â””â”€ If <5 articles or quality fail â†’ Try Priority 3             â”‚   â”‚
â”‚  â”‚                                                                  â”‚   â”‚
â”‚  â”‚  Priority 3: HTML Scraper (Deep extraction)                     â”‚   â”‚
â”‚  â”‚  â”œâ”€ Scrape homepage for article links                           â”‚   â”‚
â”‚  â”‚  â”œâ”€ Extract content from each article page                      â”‚   â”‚
â”‚  â”‚  â””â”€ Return any articles found (always fallback)                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                              â”‚
â”‚                           â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  â€¢ Sort by published_at (newest first)                           â”‚   â”‚
â”‚  â”‚  â€¢ Limit to requested count                                      â”‚   â”‚
â”‚  â”‚  â€¢ Cache results (5 min TTL)                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Fetching & Filtering Rules

### ğŸ”¹ Rule 1: 15-Day Default Cap for "Recent" News
**When user says**: "recent", "top", "latest" news/articles (without specifying days)

**Behavior**: 
- Automatically fetch only from **last 15 days**
- Hard cap: Cannot exceed 15 days even if user requests more (unless explicit `lastNDays` parameter)
- Default article count: **10 articles**

**Examples**:
```
User: "Get recent AI news"          â†’ Last 15 days, 10 articles
User: "Top news from TechCrunch"    â†’ Last 15 days, 10 articles
User: "Latest articles about India" â†’ Last 15 days, 10 articles
```

### ğŸ”¹ Rule 2: Reverse Chronological Order (Newest First)
**Guarantee**: Latest article is **always** fetched first

**Behavior**:
- All articles sorted by `published_at` in descending order
- Most recent article = index 0
- Oldest article = last index

**Example**:
```json
{
  "articles": [
    {"title": "Breaking: AI Breakthrough", "published_at": "2024-12-08T10:00:00Z"},  // â† Newest
    {"title": "Tech Update Yesterday", "published_at": "2024-12-07T15:30:00Z"},
    {"title": "News from 3 days ago", "published_at": "2024-12-05T09:00:00Z"}       // â† Oldest
  ]
}
```

### ğŸ”¹ Rule 3: Priority-Based Source Fallback
**When to check next priority**: Only if required number of articles **not** fetched from current priority

**Threshold**: Minimum **5 articles** before considering current priority successful

**Behavior**:
1. Try Priority 1 (Official RSS feeds) - fetch all feeds in parallel
2. If < 5 articles â†’ Try Priority 2 (Google News RSS)
3. If < 5 articles OR Google News quality fails â†’ Try Priority 3 (Scraper)
4. Always keep best fallback if no priority meets threshold

**Example Flow**:
```
Priority 1 (RSS): 3 articles found    â†’ < 5, try next priority
Priority 2 (Google): 8 articles found â†’ â‰¥ 5, SUCCESS! Return these 8 articles
```

### ğŸ”¹ Rule 4: No Data > 15 Days by Default
**Default behavior**: Never fetch articles older than 15 days

**Exceptions**: 
- User explicitly sets `lastNDays` parameter (e.g., `lastNDays=30`)
- User provides complete article URL directly

**Date filtering**:
- Published date parsed from RSS/HTML
- Age calculated from current UTC time
- Articles > 15 days automatically excluded (unless user overrides)

### ğŸ”¹ Rule 5: Comprehensive Filtering (8 Criteria)

| Filter Type | How It Works | Example |
|-------------|--------------|---------|
| **Days** | Reject articles older than `lastNDays` | `lastNDays=7` â†’ Only last 7 days |
| **Topic** | Keyword search in title/summary/tags | `topic="AI"` â†’ Match "AI", "artificial intelligence" |
| **Location** | Keyword search in article text | `location="India"` â†’ Match "India", "Indian", "Mumbai" |
| **Site Priority** | Fetch from top-rated sources first | Priority 1-6 sites for `get_top_news()` |
| **URL Dedup** | Track URLs in `seen_urls` set | Normalize & compare URLs |
| **Title Dedup** | Fuzzy title matching | "AI Breakthrough" vs "AI BREAKTHROUGH!" â†’ duplicate |
| **Response Time** | 2s timeout per source, 10s per priority group | Slow sources skipped |
| **Article Count** | Limit to `count` parameter | `count=5` â†’ Return max 5 articles |

### ğŸ”¹ Rule 6: Parallel & Random Fetching
**Parallelization**: All sources at **same priority level** fetched simultaneously

**Implementation**:
- `ThreadPoolExecutor` with max **8 workers**
- Timeout: **10 seconds** per priority group
- Deduplication: Remove URL & title duplicates across all parallel results

**Example** (Priority 1 with 5 RSS feeds):
```
Thread 1: Fetch RSS Feed 1 â†’ 10 articles
Thread 2: Fetch RSS Feed 2 â†’ 8 articles   } All fetched in parallel
Thread 3: Fetch RSS Feed 3 â†’ 12 articles  } (~1-2 seconds total)
Thread 4: Fetch RSS Feed 4 â†’ 5 articles
Thread 5: Fetch RSS Feed 5 â†’ 9 articles

Combined: 44 articles â†’ Deduplicate â†’ 26 unique articles
```

### ğŸ”¹ Rule 7: Google News Quality Controls
**Problem**: Google News RSS often returns redirect URLs (e.g., `news.google.com/rss/articles/...`)

**Solution**: Quality validation & fallback

**Quality Check Process**:
1. Sample first 5 articles from Google News results
2. Attempt to resolve redirect URLs (2s timeout each)
3. Count how many have valid, direct URLs (not `news.google.com`)
4. If < 50% valid â†’ Treat as failure, fallback to Priority 3 (Scraper)
5. If â‰¥ 50% valid â†’ Use Google News results

**Additional Checks**:
- No articles older than 15 days (default)
- Redirect resolution with timeout
- Automatic fallback if quality fails

### ğŸ”¹ Rule 8: Explicit-Only Sites with Partial Matching
**Two types of sites**:
1. **Priority sites** (6 configured): Used for `get_top_news()`
2. **Explicit-only sites** (39 configured): Accessed only when user specifies domain

**Flexible domain matching** for explicit sites:
- Exact match: `openai.com` â†’ `openai.com` âœ…
- Partial match: `openai` â†’ `openai.com` âœ…
- www prefix: `www.openai.com` â†’ `openai.com` âœ…

**Examples**:
```
User: "News from openai"      â†’ Matches openai.com
User: "Top articles from wired" â†’ Matches wired.com
User: "Get techcrunch news"   â†’ Matches techcrunch.com
```

### ğŸ”¹ Rule 9: Priority Sites for Top News
**get_top_news() behavior**: Fetch from **6 priority sites** (expandable to 12)

**Current Priority Sites**:
1. ndtv.com (priority 1)
2. indianexpress.com (priority 2)
3. timesofindia.indiatimes.com (priority 3)
4. hindustantimes.com (priority 4)
5. gadgets360.com (priority 5)
6. economictimes.indiatimes.com (priority 6)

**Process**:
- Fetch from each priority site in parallel
- Apply topic/location/date filters
- Combine & deduplicate results
- Sort newest first
- Return top N articles (default: 10)

**Example**:
```
User: "Get top 10 news"
â†’ Fetch from all 6 priority sites in parallel
â†’ Combine ~30-50 articles
â†’ Filter, deduplicate, sort newest first
â†’ Return top 10 articles
```


## ğŸš€ Quick Start

### Installation

```bash
# Install dependencies
pip install -r requirements.txt
```

### MCP Server Setup (For AI Assistants)

Add to your MCP configuration (e.g., `%APPDATA%\Code\User\globalStorage\saoudrizwan.claude-dev\settings\cline_mcp_settings.json`):

```json
{
  "mcpServers": {
    "news-nexus": {
      "command": "python",
      "args": ["C:\\Swdtools\\NewsNexus\\main.py"]
    }
  }
}
```

### Usage Examples

#### Get Articles from Specific Domain
```python
# Partial domain matching
get_articles(domain="openai", count=5)  # Matches openai.com
get_articles(domain="wired", count=10)  # Matches wired.com

# With filters
get_articles(
    domain="techcrunch",
    topic="AI",           # Filter by topic
    location="India",     # Filter by location
    lastNDays=7,          # Last 7 days only
    count=15              # Return 15 articles
)
```

#### Get Top News from Priority Sites
```python
# Default: 10 articles from last 15 days
get_top_news()

# With filters
get_top_news(
    count=20,            # Return 20 articles
    topic="technology",   # Filter by topic
    location="India",     # Filter by location
    lastNDays=3          # Last 3 days only
)
```

#### Health Check
```python
health_check()  # Returns server status, domain count, cache info
```

#### Get Metrics
```python
get_metrics()  # Returns performance metrics, counters, histograms
```

## ğŸ“Š Sites Configuration

### Total Domains: 45

#### Priority Sites (6) - Used by `get_top_news()`
1. ndtv.com (priority 1) - 5 RSS feeds
2. indianexpress.com (priority 2) - 5 RSS feeds
3. timesofindia.indiatimes.com (priority 3) - 5 RSS feeds
4. hindustantimes.com (priority 4) - 2 RSS feeds
5. gadgets360.com (priority 5) - 2 RSS feeds
6. economictimes.indiatimes.com (priority 6) - 5 RSS feeds

**Total RSS feeds**: 24 across 6 priority sites

#### Explicit-Only Sites (39)
Accessed only when user specifies domain name (supports partial matching):

**Technology & AI**: analyticsindiamag.com, indiatechnologynews.in, wired.com, theverge.com, techradar.com, techrepublic.com, devshorts.in, venturebeat.com, xda-developers.com, cnet.com, gizmodo.com, engadget.com, zdnet.com

**AI Research**: research.google, analyticsvidhya.com, kdnuggets.com, infoworld.com, artificialintelligence-news.com, techbuzz.ai, openai.com, deepmind.google, huggingface.co

**Developer**: github.blog, hackernoon.com

**General News**: bbc.co.uk, news.google.com, theguardian.com, sportskeeda.com

**How-To & Lifestyle**: howtogeek.com, wonderhowto.com, lifehacker.com, creatoreconomy.so

**Tech News**: techcrunch.com, mashable.com, androidpolice.com, aitechin.substack.com, business-standard.com

**Community**: news.ycombinator.com (Hacker News)

### Multi-Feed Sites (7 sites with 26 total RSS feeds)
These sites use **multiple RSS feeds fetched in parallel** for comprehensive coverage:

| Site | RSS Feeds | Example Feeds |
|------|-----------|---------------|
| ndtv.com | 5 | Top Stories, Latest News, Trending, Gadgets, Sports |
| indianexpress.com | 5 | Cricket, Trending, Technology, Tech News, AI |
| timesofindia.indiatimes.com | 5 | Top Stories, Most Recent, India, Cities, Tech |
| hindustantimes.com | 2 | India News, Technology |
| gadgets360.com | 2 | All Feeds, News |
| economictimes.indiatimes.com | 5 | Default, Markets, Market Data, Tech, AI |
| venturebeat.com | 2 | Main Feed, AI Category |


## ğŸ“– Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `NEWSNEXUS_LOG_LEVEL` | `INFO` | Logging level (DEBUG, INFO, WARNING, ERROR) |
| `NEWSNEXUS_MAX_ARTICLES` | `50` | Maximum articles per request |
| `NEWSNEXUS_CACHE_TTL` | `300` | Cache TTL in seconds (5 minutes) |
| `NEWSNEXUS_RATE_LIMIT` | `10` | Max requests per window per domain |
| `NEWSNEXUS_RATE_WINDOW` | `60` | Rate limit window in seconds |
| `NEWSNEXUS_PARALLEL` | `true` | Enable parallel source fetching |
| `NEWSNEXUS_CONFIG_PATH` | `./sites.json` | Path to sites configuration |
| `NEWSNEXUS_DEEP_SCRAPE` | `true` | Enable deep HTML scraping |
| `NEWSNEXUS_DEEP_SCRAPE_MAX` | `10` | Max articles for deep scraping |
| `NEWSNEXUS_DEEP_WORKERS` | `5` | Parallel workers for scraping |

### Core Constants (Hardcoded in main.py)

| Constant | Value | Description |
|----------|-------|-------------|
| `MAX_RECENT_DAYS` | `15` | Hard cap for "recent" news (days) |
| `DEFAULT_ARTICLE_COUNT` | `10` | Default articles when user doesn't specify |
| `MIN_ARTICLES_THRESHOLD` | `5` | Minimum articles before trying next priority |
| `DEFAULT_TIMEOUT_MS` | `2000` | Default timeout per source (milliseconds) |
| `TOP_NEWS_SITE_LIMIT` | `12` | Max priority sites for get_top_news() |

### Site Configuration (`sites.json`)

Each site has multiple sources with priority levels:

```json
{
  "name": "NDTV Multi-Feed",
  "domain": "ndtv.com",
  "priority": 1,
  "sources": [
    {"type": "official_rss", "url": "https://feeds.feedburner.com/ndtvnews-top-stories", "priority": 1, "timeout_ms": 2000},
    {"type": "official_rss", "url": "https://feeds.feedburner.com/ndtvnews-latest", "priority": 1, "timeout_ms": 2000},
    {"type": "google_news", "url": "https://news.google.com/rss/search?q=site:ndtv.com&hl=en", "priority": 2, "timeout_ms": 2000},
    {"type": "scraper", "url": "https://www.ndtv.com/", "priority": 3, "timeout_ms": 2000}
  ]
}
```

**Source Types**:
- `official_rss`: Direct RSS feed from publisher
- `google_news`: Google News RSS for the domain
- `scraper`: HTML scraping fallback

**Priority Levels**:
- Priority 1: Official RSS feeds (fastest, most reliable)
- Priority 2: Google News RSS (quality-checked)
- Priority 3: HTML Scraper (slowest, most comprehensive)


## ğŸ”§ MCP Tools Reference

### `get_articles`

Retrieve articles from a specific domain using multi-feed parallel fetching and 3-priority fallback.

**Parameters:**
| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `domain` | string | âœ… | - | Domain name (supports partial matching: 'openai' â†’ 'openai.com') |
| `topic` | string | âŒ | null | Filter by keyword in title/summary/tags |
| `location` | string | âŒ | null | Filter by location keyword |
| `lastNDays` | integer | âŒ | 15 | Date range filter (1-365 days, capped at 15 by default) |
| `count` | integer | âŒ | 10 | Number of articles to return (max 100) |

**Example Request:**
```json
{
  "domain": "techcrunch",
  "topic": "AI",
  "location": "India",
  "lastNDays": 7,
  "count": 15
}
```

**Example Response:**
```json
{
  "sourceUsed": "priority_1 [official_rss, official_rss, official_rss]",
  "articles": [
    {
      "title": "OpenAI Launches GPT-5 in India",
      "url": "https://techcrunch.com/2024/12/08/openai-gpt5-india",
      "published_at": "2024-12-08T10:00:00+00:00",
      "summary": "OpenAI announced the launch of GPT-5 with special features for Indian languages...",
      "author": "John Doe",
      "tags": ["AI", "OpenAI", "India", "GPT-5"],
      "source_domain": "techcrunch.com"
    }
  ],
  "cached": false,
  "durationMs": 1245.5
}
```

**Behavior**:
- Default 15-day cap for "recent" news
- Parallel multi-feed fetching (if site has multiple RSS feeds)
- 3-priority fallback: RSS â†’ Google News (quality-checked) â†’ Scraper
- Threshold-based: â‰¥5 articles needed to skip next priority
- Deduplication by URL and title
- Sorted newest first

---

### `get_top_news`

Get top news from priority sites (6 configured, expandable to 12).

**Parameters:**
| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `count` | integer | âŒ | 10 | Number of articles to return (max 100) |
| `topic` | string | âŒ | null | Filter by keyword in title/summary/tags |
| `location` | string | âŒ | null | Filter by location keyword |
| `lastNDays` | integer | âŒ | 15 | Date range filter (1-365 days, capped at 15 by default) |

**Example Request:**
```json
{
  "count": 20,
  "topic": "technology",
  "location": "India",
  "lastNDays": 3
}
```

**Example Response:**
```json
{
  "sources_used": [
    "ndtv.com (priority_1)",
    "indianexpress.com (priority_1)",
    "timesofindia.indiatimes.com (priority_1)",
    "hindustantimes.com (priority_1)",
    "gadgets360.com (priority_1)",
    "economictimes.indiatimes.com (priority_1)"
  ],
  "articles": [
    {
      "title": "India's Tech Boom Continues",
      "url": "https://ndtv.com/india-news/tech-boom-2024-12-08",
      "published_at": "2024-12-08T09:00:00+00:00",
      "summary": "India's technology sector saw record growth...",
      "source_domain": "ndtv.com",
      "tags": ["technology", "India", "economy"]
    }
  ],
  "cached": false,
  "total_articles": 20,
  "durationMs": 2340.8
}
```

**Behavior**:
- Fetches from 6 priority sites in parallel
- Combines results from all sites
- Deduplicates by URL and title
- Filters by topic, location, date
- Sorts newest first
- Returns top N articles

---

### `health_check`

Check server health and configuration status.

**Parameters:** None

**Example Response:**
```json
{
  "status": "healthy",
  "version": "2.0.0",
  "configured_domains": 45,
  "priority_sites": 6,
  "explicit_sites": 39,
  "multi_feed_sites": 7,
  "total_rss_feeds": 26,
  "cache": {
    "size": 12,
    "ttl_seconds": 300,
    "max_size": 1000
  },
  "constants": {
    "MAX_RECENT_DAYS": 15,
    "DEFAULT_ARTICLE_COUNT": 10,
    "MIN_ARTICLES_THRESHOLD": 5
  },
  "timestamp": "2024-12-08T10:00:00+00:00"
}
```

---

### `get_metrics`

Get detailed server metrics for monitoring and observability.

**Parameters:** None

**Example Response:**
```json
{
  "metrics": {
    "uptime_seconds": 3600,
    "counters": {
      "get_articles_requests": 150,
      "get_articles_success": 145,
      "get_articles_domain_not_found": 3,
      "get_top_news_requests": 50,
      "cache_hits": 60,
      "cache_misses": 90,
      "fetch_success": 200,
      "fetch_error": 5
    },
    "histograms": {
      "get_articles_duration_ms": {
        "count": 150,
        "min": 120,
        "max": 2500,
        "avg": 1350,
        "p50": 1200,
        "p95": 2000,
        "p99": 2400
      },
      "get_top_news_duration_ms": {
        "count": 50,
        "min": 1800,
        "max": 4500,
        "avg": 2300,
        "p50": 2200,
        "p95": 3500,
        "p99": 4200
      }
    }
  },
  "timestamp": "2024-12-08T10:00:00+00:00"
}
```


## ğŸ§ª Testing & Verification

### Test Files

**Production Tests:**
- `verify_production.py` - Production configuration verification
- `test_all_domains.py` - Test all 45 configured domains
- `test_multifeed.py` - Multi-feed parallel fetching tests

**Run Tests:**
```bash
# Verify production configuration
python verify_production.py

# Test all domains
python test_all_domains.py

# Test multi-feed architecture
python test_multifeed.py
```

### Production Verification Results

âœ… **Configuration Loading**: 45 domains, 6 priority, 39 explicit  
âœ… **get_top_news()**: 5 articles from 6 priority sites  
âœ… **Flexible Matching**: All partial domain tests passed  
âœ… **Multi-Feed**: 26 articles from 7 sites, 0 duplicates, 7.7s total  
âœ… **All Requirements**: 9/9 verified and implemented

## ğŸ“ Project Structure

```
NewsNexus/
â”œâ”€â”€ main.py                          # MCP server (production-ready)
â”œâ”€â”€ sites.json                       # 45 domains configuration
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ REQUIREMENTS_VERIFICATION.md     # Detailed requirements report
â”œâ”€â”€ MIGRATION_COMPLETE.md            # Migration documentation
â”œâ”€â”€ FILTERING_GUIDE.md               # Comprehensive filtering guide
â”œâ”€â”€ verify_production.py             # Production verification script
â”œâ”€â”€ test_all_domains.py              # Test all domains
â”œâ”€â”€ test_multifeed.py                # Multi-feed tests
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_main.py                 # Unit tests
â””â”€â”€ __pycache__/
```

## ğŸ“Š Performance Metrics

### Typical Response Times

| Operation | Avg Time | P95 Time | Notes |
|-----------|----------|----------|-------|
| Single domain (RSS hit) | 1.2s | 2.0s | Official RSS feed |
| Single domain (Google News) | 1.8s | 2.5s | With quality check |
| Single domain (Scraper) | 2.5s | 3.5s | Deep HTML extraction |
| Multi-feed (6 feeds) | 1.3s | 2.2s | Parallel fetching |
| get_top_news() (6 sites) | 2.3s | 3.5s | Parallel multi-site |

### Multi-Feed Performance

- **7 sites** with 26 total RSS feeds
- **Parallel workers**: 8 max concurrent threads
- **Average**: ~1.3s per multi-feed site
- **Deduplication**: 0 duplicates across feeds
- **Example**: NDTV (5 feeds) â†’ 10 unique articles in 1.5s

## ğŸ”’ Security Features

1. **Input Validation**
   - Domain format validation (regex, length checks)
   - URL security (blocks file://, javascript:, private IPs)
   - Parameter sanitization (XSS prevention)
   - Length limits on all inputs (max 500 chars)

2. **Rate Limiting**
   - Per-domain request limits (10 req/60s default)
   - Sliding window algorithm
   - Configurable via environment variables

3. **Error Handling**
   - Specific exception types (no broad catches)
   - Proper JSON-RPC error codes
   - No sensitive info in error messages
   - Structured logging with metrics

4. **Content Filtering**
   - URL normalization & deduplication
   - Title fuzzy matching
   - Date validation (no future dates)
   - Source quality checks

## ğŸš€ Production Deployment

### Requirements

- Python 3.13+
- 512 MB RAM minimum (1 GB recommended)
- 100 MB disk space
- Internet connection (for fetching articles)

### Environment Setup

```bash
# Set environment variables (optional)
export NEWSNEXUS_LOG_LEVEL=INFO
export NEWSNEXUS_CACHE_TTL=300
export NEWSNEXUS_MAX_ARTICLES=50

# Run MCP server
python main.py
```

### MCP Integration

Add to your MCP configuration file:

**Claude Desktop** (`%APPDATA%\Claude\config.json`):
```json
{
  "mcpServers": {
    "news-nexus": {
      "command": "python",
      "args": ["C:\\Swdtools\\NewsNexus\\main.py"]
    }
  }
}
```

**GitHub Copilot / VS Code** (`.vscode/mcp_settings.json`):
```json
{
  "mcpServers": {
    "news-nexus": {
      "command": "python",
      "args": ["C:\\Swdtools\\NewsNexus\\main.py"]
    }
  }
}
```

### Monitoring & Observability

```python
# Check health
health_check()

# Get metrics
metrics = get_metrics()
print(f"Uptime: {metrics['uptime_seconds']}s")
print(f"Success rate: {metrics['counters']['get_articles_success'] / metrics['counters']['get_articles_requests'] * 100}%")
print(f"Cache hit rate: {metrics['counters']['cache_hits'] / (metrics['counters']['cache_hits'] + metrics['counters']['cache_misses']) * 100}%")
```

## ğŸ’¡ Best Practices

### For Users

1. **Use partial domain names** for convenience: `openai` instead of `openai.com`
2. **Specify topic and location** for better filtering
3. **Use lastNDays** parameter for specific date ranges
4. **Start with get_top_news()** for general news browsing
5. **Check health_check()** if experiencing issues

### For Developers

1. **Add new domains to sites.json** with proper priority levels
2. **Test with verify_production.py** after configuration changes
3. **Monitor metrics** using get_metrics() for performance insights
4. **Use structured logging** for debugging (set LOG_LEVEL=DEBUG)
5. **Configure caching** appropriately for your use case

## ğŸ†• Recent Updates (v2.0)

- âœ… **Priority-grouped parallel fetching** (faster multi-feed)
- âœ… **Flexible domain matching** (partial names supported)
- âœ… **Google News quality controls** (redirect URL filtering)
- âœ… **15-day default cap** for recent news
- âœ… **Threshold-based fallback** (â‰¥5 articles minimum)
- âœ… **8-layer filtering engine** (comprehensive)
- âœ… **6 priority sites** for top news (expandable to 12)
- âœ… **26 RSS feeds** across 7 multi-feed sites
- âœ… **Reverse chronological** sorting (newest first)

## ğŸ“ License

MIT License - see LICENSE for details

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Submit a pull request

---

**Built for the MCP ecosystem** | **Production-ready** | **Fast & Reliable**

For detailed technical documentation, see:
- `REQUIREMENTS_VERIFICATION.md` - Full requirements verification
- `FILTERING_GUIDE.md` - Comprehensive filtering guide
- `MIGRATION_COMPLETE.md` - Migration documentation
